{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LS_DS_231.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArmandoSep/DS-Unit-2-Applied-Modeling/blob/master/module1-define-ml-problems/LS_DS_231.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MX6TsRNoej9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 1*\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG4by4hAoej-",
        "colab_type": "text"
      },
      "source": [
        "# Define ML problems\n",
        "- Choose a target to predict, and check its distribution\n",
        "- Avoid leakage of information from test to train or from target to features\n",
        "- Choose an appropriate evaluation metric\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtoaEjF9oej_",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwclwRSHoej_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw9G3Q8SoekC",
        "colab_type": "text"
      },
      "source": [
        "# Choose a target to predict, and check its distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcEJaRRBoekD",
        "colab_type": "text"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubat3m6EoekE",
        "colab_type": "text"
      },
      "source": [
        "This is the data science process at a high level:\n",
        "\n",
        "<img src=\"https://image.slidesharecdn.com/becomingadatascientistadvice-pydatadc-shared-161012184823/95/becoming-a-data-scientist-advice-from-my-podcast-guests-55-638.jpg?cb=1476298295\">\n",
        "\n",
        "—Renee Teate, [Becoming a Data Scientist, PyData DC 2016 Talk](https://www.becomingadatascientist.com/2016/10/11/pydata-dc-2016-talk/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5VGbEF8oekE",
        "colab_type": "text"
      },
      "source": [
        "We've focused on the 2nd arrow in the diagram, by training predictive models. Now let's zoom out and focus on the 1st arrow: defining problems, by translating business questions into code/data questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQUDttbloekF",
        "colab_type": "text"
      },
      "source": [
        "Last sprint, you did a Kaggle Challenge. It’s a great way to practice model validation and other technical skills. But that's just part of the modeling process. [Kaggle gets critiqued](https://speakerdeck.com/szilard/machine-learning-software-in-practice-quo-vadis-invited-talk-kdd-conference-applied-data-science-track-august-2017-halifax-canada?slide=119) because some things are done for you: Like [**defining the problem!**](https://www.linkedin.com/pulse/data-science-taught-universities-here-why-maciej-wasiak/) In today’s module, you’ll begin to practice this objective, with your dataset you’ve chosen for your personal portfolio project.\n",
        "\n",
        "When defining a supervised machine learning problem, one of the first steps is choosing a target to predict."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLLe8oXtoekF",
        "colab_type": "text"
      },
      "source": [
        "Which column in your tabular dataset will you predict?\n",
        "\n",
        "Is your problem regression or classification? You have options. Sometimes it’s not straightforward, as we'll see below.\n",
        "\n",
        "- Discrete, ordinal, low cardinality target: Can be regression or multi-class classification.\n",
        "- (In)equality comparison: Converts regression or multi-class classification to binary classification.\n",
        "- Predicted probability: Seems to [blur](https://brohrer.github.io/five_questions_data_science_answers.html) the line between classification and regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWncQci-oekF",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyF16VVmoekG",
        "colab_type": "text"
      },
      "source": [
        "Let's reuse the [Burrito reviews dataset.](https://nbviewer.jupyter.org/github/LambdaSchool/DS-Unit-2-Linear-Models/blob/master/module4-logistic-regression/LS_DS_214_assignment.ipynb) 🌯\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "0U6cY48XoekH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "pd.options.display.max_columns = None\n",
        "df = pd.read_csv(DATA_PATH+'burritos/burritos.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ1UnopooekK",
        "colab_type": "text"
      },
      "source": [
        "### Choose your target \n",
        "\n",
        "Which column in your tabular dataset will you predict?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "DSlTb4KCoekL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "fa784b7b-a6f1-4b82-ac0f-1df336634440"
      },
      "source": [
        "df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Location</th>\n",
              "      <th>Burrito</th>\n",
              "      <th>Date</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Address</th>\n",
              "      <th>URL</th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>overall</th>\n",
              "      <th>Rec</th>\n",
              "      <th>Reviewer</th>\n",
              "      <th>Notes</th>\n",
              "      <th>Unreliable</th>\n",
              "      <th>NonSD</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Chicken</th>\n",
              "      <th>Shrimp</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Rice</th>\n",
              "      <th>Beans</th>\n",
              "      <th>Lettuce</th>\n",
              "      <th>Tomato</th>\n",
              "      <th>Bell peper</th>\n",
              "      <th>Carrots</th>\n",
              "      <th>Cabbage</th>\n",
              "      <th>Sauce</th>\n",
              "      <th>Salsa.1</th>\n",
              "      <th>Cilantro</th>\n",
              "      <th>Onion</th>\n",
              "      <th>Taquito</th>\n",
              "      <th>Pineapple</th>\n",
              "      <th>Ham</th>\n",
              "      <th>Chile relleno</th>\n",
              "      <th>Nopales</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donato's taco shop</td>\n",
              "      <td>California</td>\n",
              "      <td>1/18/2016</td>\n",
              "      <td>Miramar</td>\n",
              "      <td>6780 Miramar Rd</td>\n",
              "      <td>http://donatostacoshop.net/</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.80</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scott</td>\n",
              "      <td>good fries: 4/5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Oscar's Mexican food</td>\n",
              "      <td>California</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>San Marcos</td>\n",
              "      <td>225 S Rancho Santa Fe Rd</td>\n",
              "      <td>http://www.yelp.com/biz/oscars-mexican-food-sa...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scott</td>\n",
              "      <td>Fries: 3/5; too little meat</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Oscar's Mexican food</td>\n",
              "      <td>Carnitas</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Emily</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Oscar's Mexican food</td>\n",
              "      <td>Carne asada</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ricardo</td>\n",
              "      <td>Go to average burrito place like Rigoberto's i...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pollos Maria</td>\n",
              "      <td>California</td>\n",
              "      <td>1/27/2016</td>\n",
              "      <td>Carlsbad</td>\n",
              "      <td>3055 Harding St</td>\n",
              "      <td>http://pollosmaria.com/</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>x</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scott</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>Valentine's Mexican Food</td>\n",
              "      <td>Al Pastor</td>\n",
              "      <td>8/27/2019</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.0</td>\n",
              "      <td>20.5</td>\n",
              "      <td>0.57</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Anon</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>Valentine's Mexican Food</td>\n",
              "      <td>Chile Relleno</td>\n",
              "      <td>8/27/2019</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1.02</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bonnie</td>\n",
              "      <td>non-symmetric wrapping</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>Valentine's Mexican Food</td>\n",
              "      <td>California</td>\n",
              "      <td>8/27/2019</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.90</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.77</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Scott</td>\n",
              "      <td>way too small and not enough meat</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>Valentine's Mexican Food</td>\n",
              "      <td>Shrimp</td>\n",
              "      <td>8/27/2019</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.90</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22.5</td>\n",
              "      <td>24.5</td>\n",
              "      <td>1.07</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AC</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>Valentine's Mexican Food</td>\n",
              "      <td>Pollo Asado</td>\n",
              "      <td>8/27/2019</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.0</td>\n",
              "      <td>21.3</td>\n",
              "      <td>0.61</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.60</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sisi</td>\n",
              "      <td>i wish there was some really bomb hot sauce, t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>423 rows × 66 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Location        Burrito       Date Neighborhood  \\\n",
              "0          Donato's taco shop    California   1/18/2016      Miramar   \n",
              "1        Oscar's Mexican food    California   1/24/2016   San Marcos   \n",
              "2        Oscar's Mexican food       Carnitas  1/24/2016          NaN   \n",
              "3        Oscar's Mexican food    Carne asada  1/24/2016          NaN   \n",
              "4                Pollos Maria     California  1/27/2016     Carlsbad   \n",
              "..                        ...            ...        ...          ...   \n",
              "418  Valentine's Mexican Food      Al Pastor  8/27/2019          NaN   \n",
              "419  Valentine's Mexican Food  Chile Relleno  8/27/2019          NaN   \n",
              "420  Valentine's Mexican Food     California  8/27/2019          NaN   \n",
              "421  Valentine's Mexican Food         Shrimp  8/27/2019          NaN   \n",
              "422  Valentine's Mexican Food    Pollo Asado  8/27/2019          NaN   \n",
              "\n",
              "                      Address  \\\n",
              "0             6780 Miramar Rd   \n",
              "1    225 S Rancho Santa Fe Rd   \n",
              "2                         NaN   \n",
              "3                         NaN   \n",
              "4             3055 Harding St   \n",
              "..                        ...   \n",
              "418                       NaN   \n",
              "419                       NaN   \n",
              "420                       NaN   \n",
              "421                       NaN   \n",
              "422                       NaN   \n",
              "\n",
              "                                                   URL  Yelp  Google Chips  \\\n",
              "0                          http://donatostacoshop.net/   3.5     4.2   NaN   \n",
              "1    http://www.yelp.com/biz/oscars-mexican-food-sa...   3.5     3.3   NaN   \n",
              "2                                                  NaN   NaN     NaN   NaN   \n",
              "3                                                  NaN   NaN     NaN   NaN   \n",
              "4                              http://pollosmaria.com/   4.0     3.8     x   \n",
              "..                                                 ...   ...     ...   ...   \n",
              "418                                                NaN   NaN     NaN   NaN   \n",
              "419                                                NaN   NaN     NaN   NaN   \n",
              "420                                                NaN   NaN     NaN   NaN   \n",
              "421                                                NaN   NaN     NaN   NaN   \n",
              "422                                                NaN   NaN     NaN   NaN   \n",
              "\n",
              "     Cost  Hunger  Mass (g)  Density (g/mL)  Length  Circum  Volume  Tortilla  \\\n",
              "0    6.49     3.0       NaN             NaN     NaN     NaN     NaN       3.0   \n",
              "1    5.45     3.5       NaN             NaN     NaN     NaN     NaN       2.0   \n",
              "2    4.85     1.5       NaN             NaN     NaN     NaN     NaN       3.0   \n",
              "3    5.25     2.0       NaN             NaN     NaN     NaN     NaN       3.0   \n",
              "4    6.59     4.0       NaN             NaN     NaN     NaN     NaN       4.0   \n",
              "..    ...     ...       ...             ...     ...     ...     ...       ...   \n",
              "418  6.00     1.0       NaN             NaN    17.0    20.5    0.57       5.0   \n",
              "419  6.00     4.0       NaN             NaN    19.0    26.0    1.02       4.0   \n",
              "420  7.90     3.0       NaN             NaN    20.0    22.0    0.77       4.0   \n",
              "421  7.90     3.0       NaN             NaN    22.5    24.5    1.07       5.0   \n",
              "422  5.50     3.5       NaN             NaN    17.0    21.3    0.61       3.0   \n",
              "\n",
              "     Temp  Meat  Fillings  Meat:filling  Uniformity  Salsa  Synergy  Wrap  \\\n",
              "0     5.0   3.0       3.5           4.0         4.0    4.0      4.0   4.0   \n",
              "1     3.5   2.5       2.5           2.0         4.0    3.5      2.5   5.0   \n",
              "2     2.0   2.5       3.0           4.5         4.0    3.0      3.0   5.0   \n",
              "3     2.0   3.5       3.0           4.0         5.0    4.0      4.0   5.0   \n",
              "4     5.0   4.0       3.5           4.5         5.0    2.5      4.5   4.0   \n",
              "..    ...   ...       ...           ...         ...    ...      ...   ...   \n",
              "418   4.0   3.5       NaN           4.0         4.0    2.0      2.0   5.0   \n",
              "419   5.0   NaN       3.5           4.0         4.0    5.0      4.0   3.0   \n",
              "420   4.0   4.0       3.7           3.0         2.0    3.5      4.0   4.5   \n",
              "421   2.0   5.0       5.0           5.0         2.0    5.0      5.0   2.0   \n",
              "422   5.0   4.3       4.0           4.9         3.8    3.0      4.5   4.0   \n",
              "\n",
              "     overall  Rec Reviewer                                              Notes  \\\n",
              "0       3.80  NaN    Scott                                    good fries: 4/5   \n",
              "1       3.00  NaN    Scott                        Fries: 3/5; too little meat   \n",
              "2       3.00  NaN    Emily                                                NaN   \n",
              "3       3.75  NaN  Ricardo  Go to average burrito place like Rigoberto's i...   \n",
              "4       4.20  NaN    Scott                                                NaN   \n",
              "..       ...  ...      ...                                                ...   \n",
              "418     3.50  NaN     Anon                                                NaN   \n",
              "419     4.00  NaN   Bonnie                             non-symmetric wrapping   \n",
              "420     3.50  NaN    Scott                  way too small and not enough meat   \n",
              "421     4.00  NaN       AC                                                NaN   \n",
              "422     4.60  NaN     Sisi  i wish there was some really bomb hot sauce, t...   \n",
              "\n",
              "    Unreliable NonSD Beef Pico Guac Cheese Fries Sour cream Pork Chicken  \\\n",
              "0          NaN   NaN    x    x    x      x     x        NaN  NaN     NaN   \n",
              "1          NaN   NaN    x    x    x      x     x        NaN  NaN     NaN   \n",
              "2          NaN   NaN  NaN    x    x    NaN   NaN        NaN    x     NaN   \n",
              "3          NaN   NaN    x    x    x    NaN   NaN        NaN  NaN     NaN   \n",
              "4          NaN   NaN    x    x  NaN      x     x        NaN  NaN     NaN   \n",
              "..         ...   ...  ...  ...  ...    ...   ...        ...  ...     ...   \n",
              "418        NaN   NaN  NaN  NaN  NaN    NaN   NaN        NaN  NaN     NaN   \n",
              "419        NaN   NaN  NaN  NaN  NaN    NaN   NaN        NaN  NaN     NaN   \n",
              "420        NaN   NaN  NaN  NaN  NaN    NaN   NaN        NaN  NaN     NaN   \n",
              "421        NaN   NaN  NaN  NaN  NaN    NaN   NaN        NaN  NaN     NaN   \n",
              "422        NaN   NaN  NaN  NaN  NaN    NaN   NaN        NaN  NaN     NaN   \n",
              "\n",
              "    Shrimp Fish Rice Beans Lettuce Tomato Bell peper Carrots Cabbage Sauce  \\\n",
              "0      NaN  NaN  NaN   NaN     NaN    NaN        NaN     NaN     NaN   NaN   \n",
              "1      NaN  NaN  NaN   NaN     NaN    NaN        NaN     NaN     NaN   NaN   \n",
              "2      NaN  NaN  NaN   NaN     NaN    NaN        NaN     NaN     NaN   NaN   \n",
              "3      NaN  NaN  NaN   NaN     NaN    NaN        NaN     NaN     NaN   NaN   \n",
              "4      NaN  NaN  NaN   NaN     NaN    NaN        NaN     NaN     NaN   NaN   \n",
              "..     ...  ...  ...   ...     ...    ...        ...     ...     ...   ...   \n",
              "418    NaN  NaN  NaN   NaN     NaN    NaN        NaN     NaN     NaN   NaN   \n",
              "419    NaN  NaN  NaN   NaN     NaN    NaN        NaN     NaN     NaN   NaN   \n",
              "420    NaN  NaN  NaN   NaN     NaN    NaN        NaN     NaN     NaN   NaN   \n",
              "421    NaN  NaN  NaN   NaN     NaN    NaN        NaN     NaN     NaN   NaN   \n",
              "422    NaN  NaN  NaN   NaN     NaN    NaN        NaN     NaN     NaN   NaN   \n",
              "\n",
              "    Salsa.1 Cilantro Onion Taquito Pineapple  Ham Chile relleno Nopales  \\\n",
              "0       NaN      NaN   NaN     NaN       NaN  NaN           NaN     NaN   \n",
              "1       NaN      NaN   NaN     NaN       NaN  NaN           NaN     NaN   \n",
              "2       NaN      NaN   NaN     NaN       NaN  NaN           NaN     NaN   \n",
              "3       NaN      NaN   NaN     NaN       NaN  NaN           NaN     NaN   \n",
              "4       NaN      NaN   NaN     NaN       NaN  NaN           NaN     NaN   \n",
              "..      ...      ...   ...     ...       ...  ...           ...     ...   \n",
              "418     NaN      NaN   NaN     NaN       NaN  NaN           NaN     NaN   \n",
              "419     NaN      NaN   NaN     NaN       NaN  NaN           NaN     NaN   \n",
              "420     NaN      NaN   NaN     NaN       NaN  NaN           NaN     NaN   \n",
              "421     NaN      NaN   NaN     NaN       NaN  NaN           NaN     NaN   \n",
              "422     NaN      NaN   NaN     NaN       NaN  NaN           NaN     NaN   \n",
              "\n",
              "    Lobster  Queso  Egg Mushroom Bacon Sushi Avocado Corn Zucchini  \n",
              "0       NaN    NaN  NaN      NaN   NaN   NaN     NaN  NaN      NaN  \n",
              "1       NaN    NaN  NaN      NaN   NaN   NaN     NaN  NaN      NaN  \n",
              "2       NaN    NaN  NaN      NaN   NaN   NaN     NaN  NaN      NaN  \n",
              "3       NaN    NaN  NaN      NaN   NaN   NaN     NaN  NaN      NaN  \n",
              "4       NaN    NaN  NaN      NaN   NaN   NaN     NaN  NaN      NaN  \n",
              "..      ...    ...  ...      ...   ...   ...     ...  ...      ...  \n",
              "418     NaN    NaN  NaN      NaN   NaN   NaN     NaN  NaN      NaN  \n",
              "419     NaN    NaN  NaN      NaN   NaN   NaN     NaN  NaN      NaN  \n",
              "420     NaN    NaN  NaN      NaN   NaN   NaN     NaN  NaN      NaN  \n",
              "421     NaN    NaN  NaN      NaN   NaN   NaN     NaN  NaN      NaN  \n",
              "422     NaN    NaN  NaN      NaN   NaN   NaN     NaN  NaN      NaN  \n",
              "\n",
              "[423 rows x 66 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB-9WOD4qmfM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "197746b2-8adb-4da0-a6cd-3fb215494c55"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Location', 'Burrito', 'Date', 'Neighborhood', 'Address', 'URL', 'Yelp',\n",
              "       'Google', 'Chips', 'Cost', 'Hunger', 'Mass (g)', 'Density (g/mL)',\n",
              "       'Length', 'Circum', 'Volume', 'Tortilla', 'Temp', 'Meat', 'Fillings',\n",
              "       'Meat:filling', 'Uniformity', 'Salsa', 'Synergy', 'Wrap', 'overall',\n",
              "       'Rec', 'Reviewer', 'Notes', 'Unreliable', 'NonSD', 'Beef', 'Pico',\n",
              "       'Guac', 'Cheese', 'Fries', 'Sour cream', 'Pork', 'Chicken', 'Shrimp',\n",
              "       'Fish', 'Rice', 'Beans', 'Lettuce', 'Tomato', 'Bell peper', 'Carrots',\n",
              "       'Cabbage', 'Sauce', 'Salsa.1', 'Cilantro', 'Onion', 'Taquito',\n",
              "       'Pineapple', 'Ham', 'Chile relleno', 'Nopales', 'Lobster', 'Queso',\n",
              "       'Egg', 'Mushroom', 'Bacon', 'Sushi', 'Avocado', 'Corn', 'Zucchini'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrDY6QXsqsqT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "63caf9db-a065-41f8-86b7-d46ff9b2a154"
      },
      "source": [
        "df['overall'].describe()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    421.000000\n",
              "mean       3.620887\n",
              "std        0.755718\n",
              "min        1.000000\n",
              "25%        3.100000\n",
              "50%        3.800000\n",
              "75%        4.100000\n",
              "max        5.000000\n",
              "Name: overall, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXiie16MrY_w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "287e5f10-f6cf-43db-89d4-c4949518a824"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.distplot(df['overall']);"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEJCAYAAACE39xMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxU9b3/8dcnk30nG4SEkAABiezEoKLWVm1Rq7R1Kaht7aK/9tbW7ldv+7Otvb97u9xr29t621Jvr9Vei9bllrYorq0rmLBD2EIIWSCQkJB9m5nP748MPmIKZICZnFk+z8cjD+acOZl5z+ORvDn5nnO+R1QVY4wx4S/G6QDGGGMCwwrdGGMihBW6McZECCt0Y4yJEFboxhgTIazQjTEmQvhV6CKyTET2iEiNiNxzkueLROQVEdksIttE5JrARzXGGHM6MtZ56CLiAvYCVwGNQCWwUlWrR2yzCtisqr8QkTJgraoWBy21McaYvxPrxzYVQI2q1gKIyGpgOVA9YhsF0n2PM4BDY71oTk6OFhcXn1FYY4yJdhs3bmxV1dyTPedPoRcADSOWG4Elo7b5DvC8iHwBSAGuHOtFi4uLqaqq8uPtjTHGnCAiB0/1XKAOiq4EHlbVQuAa4FER+bvXFpE7RaRKRKpaWloC9NbGGGPAv0JvAqaMWC70rRvp08ATAKr6FpAI5Ix+IVVdparlqlqem3vSvxiMMcacJX8KvRIoFZESEYkHVgBrRm1TD1wBICKzGS502wU3xphxNGahq6obuAtYB+wCnlDVnSJyv4hc79vsq8AdIrIV+D1wu9o0jsYYM678OSiKqq4F1o5ad9+Ix9XA0sBGM8YYcybsSlFjjIkQVujGGBMhrNCNMSZCWKEbY0yE8OugqDEmvD22of6sv/eWJUUBTGKCyfbQjTEmQlihG2NMhLBCN8aYCGGFbowxEcIK3RhjIoQVujHGRAgrdGOMiRBW6MYYEyGs0I0xJkJYoRtjTISwQjfGmAhhhW6MMRHCCt0YYyKEX4UuIstEZI+I1IjIPSd5/scissX3tVdEjgc+qjHGmNMZc/pcEXEBDwJXAY1ApYis8d1HFABV/fKI7b8ALAxCVmOMMafhzx56BVCjqrWqOgisBpafZvuVwO8DEc4YY4z//Cn0AqBhxHKjb93fEZGpQAnw8rlHM8YYcyYCfVB0BfCkqnpO9qSI3CkiVSJS1dLSEuC3NsaY6OZPoTcBU0YsF/rWncwKTjPcoqqrVLVcVctzc3P9T2mMMWZM/hR6JVAqIiUiEs9waa8ZvZGInAdMAN4KbERjjDH+GLPQVdUN3AWsA3YBT6jqThG5X0SuH7HpCmC1qmpwohpjjDmdMU9bBFDVtcDaUevuG7X8ncDFMsYYc6bsSlFjjIkQVujGGBMhrNCNMSZCWKEbY0yEsEI3xpgIYYVujDERwgrdGGMihBW6McZECCt0Y4yJEFboxhgTIazQjTEmQlihG2NMhLBCNyYKeLxKY3sv7b2DeG1C1Ijl12yLxpjwdfBYD6te3U9Dex8ALhEum5nDlbMnIiIOpzOBZIVuTAT7y7bDfOPJrXhUuX7+ZFwi7DvaxSt7WhARrpw90emIJoCs0I2JUHuPdPHlJ7YwZ3I6V86eSGZyPACLiyfwzOYmXt59lHhXDJfNtNtBRgobQzcmAg24Pdy9egvpibGs+nj5O2UOECPChxcWMLcgg3U7mzna1e9gUhNIVujGRKAHnt/LrsOd/OCGeeSkJvzd8zEiXDd/MnGxMby066gDCU0w+FXoIrJMRPaISI2I3HOKbW4WkWoR2SkijwU2pjHGXzuaOlj1Wi23LCniitOMkacmxLJ0ejbbmzo4dLxvHBOaYBmz0EXEBTwIXA2UAStFpGzUNqXAvcBSVT0f+FIQshpj/PCTF/eSlhDLPVefN+a2l8zIJTEuhhd3HRmHZCbY/NlDrwBqVLVWVQeB1cDyUdvcATyoqu0Aqmp/wxnjgG2Nx3lx11HuuHQa6YlxY26fFO/istJcdjd30dDWOw4JTTD5U+gFQMOI5UbfupFmAjNF5A0RWS8iywIV0Bjjvx+/sJfM5DhuX1rs9/dcNC2bOJdQdbAteMHMuAjUQdFYoBS4HFgJ/FpEMkdvJCJ3ikiViFS1tLQE6K2NMQCb69t5ZU8Ld142jTQ/9s5PSIhzMWdyBtubOhjyeIOY0ASbP4XeBEwZsVzoWzdSI7BGVYdU9QCwl+GCfxdVXaWq5apanptr574aE0i//Nt+MpPj+MRFxWf8vQuKMukf8rK7uSvwwcy48afQK4FSESkRkXhgBbBm1Db/y/DeOSKSw/AQTG0AcxpjTqOxvZcXqo+wsqKIlIQzv15wem4q6YmxbK5vD0I6M17GLHRVdQN3AeuAXcATqrpTRO4Xket9m60DjolINfAK8HVVPRas0MaYd3t0/UEAbrtw6ll9f4wI86dksvdIF90D7kBGM+PIr//KVXUtsHbUuvtGPFbgK74vY8w46h/y8HhlA+8vm0RBZtJZv87Cogm8tq+VbY3HuXh6TgATmvFiV4oaE+b+uKWJ471DfOLi4nN6nUnpieRnJLKtsSMwwcy4s0I3JoypKr998yDnTUrjwmlZ5/x6s/PTaWjrpceGXcKSFboxYWxbYwfVhzu59cKpAZnb/LxJaSjDMzWa8GOFbkwYe7yqgcS4GJYvmByQ15ucmURqQqydvhimrNCNCVN9gx7+tOUQ18zJ9+syf3/EiDBrYhr7jnbh8dqt6sKNFboxYerZHYfpGnBzU/mUsTc+A7MmpdE/5OVgW09AX9cEnxW6MWHq8coGpmYnB+Rg6Eileam4RNhz2IZdwo0VujFhqK61hw0H2ri5fErAb/ScEOeiJCeF3XZgNOxYoRsThp6oaiBG4IZFhUF5/VmT0mjpGqC9ZzAor2+CwwrdmDDj9nh5alMjl8/KY1JGYlDeY0ZeKgD7W7qD8vomOKzQjQkzr+5r4UjnADcH+GDoSHlpCaQkxFLbagdGw4kVujFh5vHKBrJT4nnfeXlBew8RYXpuCvtbuhmeqsmEAyt0Y8JIS9cAL+06ykcWFRAfG9xf3+m5qXT1u23YJYxYoRsTRp7Z3Ijbq3z0guANt5wwPXd4HP3N/TYTdriwQjcmTKgqT1Q1sqgokxl5aUF/vwnJcWQmx/FmjRV6uLBCNyZMbKo/Ts3R7nHZOwffOHpOKm/VHsNr0wCEBSt0Y8LEE5UNJMe7uHZeYCbi8se03BQ6+oaoPtw5bu9pzt6Z33zQGHPWHttQf1bfN+D28Odth7h2bj6pZ3HP0LN1Yhz9rf3HmFOQMW7va86OX3voIrJMRPaISI2I3HOS528XkRYR2eL7+kzgoxoTvbY3dtAz6Bm34ZYT0pPimJaTwoYDbeP6vubsjPlfvYi4gAeBq4BGoFJE1qhq9ahNH1fVu4KQ0Ziot/FgO9NyU1g8dcK4v3dFSRbP7mjG61ViYgI7b4wJLH/20CuAGlWtVdVBYDWwPLixjDEnHO3s52BbLx8NwkRc/qgoyaKjb4g9NllXyPOn0AuAhhHLjb51o90gIttE5EkRGd+/C42JYJV1bbhEuGFxcCbiGktFyfD0vG/bsEvIC9RZLn8CilV1HvAC8NuTbSQid4pIlYhUtbS0BOitjYlcQx4vG+vbKZucTk5qgiMZCickU5CZZIUeBvwp9CZg5B53oW/dO1T1mKoO+BYfAhaf7IVUdZWqlqtqeW5u7tnkNSaqbG/qoH/I+85eslMqSrLYcKDN5nUJcf4UeiVQKiIlIhIPrADWjNxARPJHLF4P7ApcRGOi19sH2shJjWdaToqjOSpKsmjtHuCAzb4Y0sYsdFV1A3cB6xgu6idUdaeI3C8i1/s2+6KI7BSRrcAXgduDFdiYaNHc0U99Wy8VxVmOHAwdycbRw4NfVyio6lpg7ah19414fC9wb2CjGRPd3q47RmyMsKho/E9VHG1aTgo5qfG8faCNFRVFTscxp2CX/hsTggbdXjbXH2dOQQbJ43hl6KmIyDvj6CZ0WaEbE4K2NR5nwO2lotjZg6EjVRRn0XS8j8b2XqejmFNw/r9+Y8zfebuujby0BKZmJ7+z7mzngQmUipJsYPi8+MIJyWNsbZxge+jGhJjhveA+KkqcPxg60qxJaaQnxtqB0RBmhW5MiHn7QBtxLmHhFOcPho7kihEuKLZx9FBmhW5MCOkb9LC14ThzCzJJinc5HefvVJRkUdvSQ0vXwNgbm3FnhW5MCKk62Magx8vF07OdjnJSJ85Hr6yzvfRQZIVuTIjweJW39h+jJCeFyZlJTsc5qTkFGSTFuWwcPURZoRsTIqoPd3K8b4ilIbp3DhDnimHx1Ak2jh6irNCNCRFv1LSSlRLPefnpTkc5rYqSLHY3d9LRO+R0FDOKFboxIaChrZf6tl4umpZNTAidqngyFSVZqA6P95vQYoVuTAh4c38rCbExlDtwi7kztWBKJvGuGBtHD0F2paiJSudy1eUtSwI7OVVH3xDbmzq4aFo2CXGhd6riaIlxLuZPybBx9BBke+jGOGx97TFU4aLpOU5H8VtFSRY7mjroGXA7HcWMYIVujIMG3V7ePtBG2eR0slLinY7jt4qSbNxeZXP9caejmBGs0I1x0OaGdvqGPFwcRnvnAIunTiBG4O0Dx5yOYkawQjfGIV5V3qhppSAzieLs8Jq9MDUhljkFNo4eaqzQjXHIjqYOWrsHuWxmbkjNquiviuIsNjccZ8DtcTqK8fGr0EVkmYjsEZEaEbnnNNvdICIqIuWBi2hM5FFV/ra3hZzUBM6fHNoXEp1KRUkWg24v2xo7nI5ifMYsdBFxAQ8CVwNlwEoRKTvJdmnA3cCGQIc0JtLsPdLF4Y5+3jMzN+QvJDqVC4rtxtGhxp899AqgRlVrVXUQWA0sP8l23wN+APQHMJ8xEUdVeWVPC5lJcSyYkul0nLM2ISWeWRPTbBw9hPhT6AVAw4jlRt+6d4jIImCKqv4lgNmMiUj7W3qob+vl0pm5uGLCc+/8hIqSLDbWteH2eJ2OYgjAQVERiQEeAL7qx7Z3ikiViFS1tLSc61sbE3ZUlReqm8lIiuOCMLjMfywVJVn0DHrYeajT6SgG/wq9CZgyYrnQt+6ENGAO8FcRqQMuBNac7MCoqq5S1XJVLc/NzT371MaEqT3NXTS09/G+WXnEusL/JLMTN7ywcfTQ4M9PVCVQKiIlIhIPrADWnHhSVTtUNUdVi1W1GFgPXK+qVUFJbEyY8nqVF3YdISslnkURsHcOMDE9keLsZBtHDxFjFrqquoG7gHXALuAJVd0pIveLyPXBDmhMpHh2RzOHO/q54ry8sB87H6miJIvKuja8XnU6StTza7ZFVV0LrB217r5TbHv5uccyJrL0D3n4/nO7yEtLYH6Yndky1syUXu/wjJE/eXEfkzIS3/VcoGemNKcX/oN4xoSB37xxgIa2Pj44b3LYnnd+KsU5KQAcONbjcBJjhW5MkB3t7OfnL9dwVdlEZuSlOh0n4CYkx5GRFEddqxW606zQjQmyH67bw5DHyzevme10lKAQEUpyUqhr7UHVxtGdZIVuTBC9vq+VJzc28ulLpr0zNBGJirNT6Bpw09o96HSUqGaFbkyQdA+4+centjEtN4UvXVnqdJygOjGUVHO0y+Ek0c0K3Zgg+Ze1uzjU0cePbpxPYhjcK/RcZKXEk5UST83RbqejRDUrdGOC4OXdR3hsQz2fuaSExRFyEdFYZuSmUtvag8fOR3eMFboxAba/pZu7f7+F8yen89X3z3I6zriZkZfKgNtLQ1uv01GilhW6MQHU1T/EnY9UER8bw6qPl0f8UMtI03NTEaCmxYZdnGKFbkyA9A95+If/2UTdsV4evHURBZlJTkcaV0nxLgonJLHviB0YdYoVujEB0D/k4Y5Hqni9ppV//chcLpyW7XQkR8zIS6OxvY++QbvPqBOs0I05Rx19Q3z6t5W8XtPKD2+Yx83lU8b+pgg1Iy8VBWpbbdjFCVboxpyD3c2dLP/562yobePfbpzPTVFc5gBFWckkxMaw14ZdHOHXbIvGmHfzepXVlQ1878/VpCXGsvrOCyn33TQ5mrlihNK8VPY0d9k0AA6wQjfmDO070sW9T2+n6mA7F0/P5icrFpCXljj2N0aJWZPS2XGok8Mddr/48WaFboyfhjxe/ra3hW+v2UFKQiw/unEeNy4uRCJsOtxzNXPi8OmLu5tt2GW8WaEb44eDx3p4alMTrd0DfHhhAd+6djbZqQlOxwpJaYlxFE5IYk+z3Th6vNlBUWNOY8jj5dkdh1n1ai1ur5dPXlzMjz+6wMp8DLMmDZ++2No94HSUqOJXoYvIMhHZIyI1InLPSZ7/rIhsF5EtIvK6iJQFPqox46ujb4hVr9by2r5WyosncPf7SimdmOZ0rLBw3qR0FPjrnhano0SVMQtdRFzAg8DVQBmw8iSF/ZiqzlXVBcAPgQcCntSYcdTY3st//rWGlu4BPnbhVD68sJCEKLqM/1zlZySSnhjLy7uPOB0lqvizh14B1KhqraoOAquB5SM3UNWRg2UpgJ2vZMLWgdYefv1aLbExwmcvm87s/HSnI4UdEWHWpHT+tqeF/iG7anS8+FPoBUDDiOVG37p3EZHPi8h+hvfQvxiYeMaMr8b2Xh55q47MpHg++57pf3cXe+O/8yen0zPo4fV9rU5HiRoBOyiqqg+q6nTgH4FvnWwbEblTRKpEpKqlxcbWTGg52tnPw2/WkRzv4lOXlJCWGOd0pLA2PTeVjKQ41u447HSUqOFPoTcBI69nLvStO5XVwIdO9oSqrlLVclUtz83N9T+lMUE2MOThdxvqiRHhU0tLyEiyMj9XrhjhytkTebH6CINur9NxooI/hV4JlIpIiYjEAyuANSM3EJGRN0y8FtgXuIjGBJeq8vTmJo51D7CiYoqdkhhA18ydRGe/mzf327DLeBiz0FXVDdwFrAN2AU+o6k4RuV9ErvdtdpeI7BSRLcBXgE8ELbExAba+9hjbmzp4//mTmJaT6nSciHJJaQ6pCbE8u73Z6ShRwa8rRVV1LbB21Lr7Rjy+O8C5jBkXLV0DPLujmfMmpXFpaY7TcSLOUxubmJ6bwp+2HWJOQQauGP+nSbhlSVEQk0Umu1LURC2vKk9vbiTOFcOHFxYQY3OyBMWcggx6Bz02R/o4sEI3UevtA20cPNbLNXPz7YyWIJo5MY2E2Bi2Nhx3OkrEs0I3Uel47yDP7WxmRl4qi4oynY4T0eJcMcwtyGDHoU472yXIrNBNVHpuZzNer/KhBQU2/e04WFCUyaDbS/Vhm4ExmKzQTdSprGtjW2MHl5bmkpUS73ScqFCcnUJmUhxbGtqdjhLRrNBNVPF6le/+aSfpibG8Z6Zd3DZeYkRYMCWTfUe66eofcjpOxLJCN1HlyY2N7GjqZNmcfOJj7cd/PC0oykSBrY0dTkeJWPYTbaJG36CHf39hDwuLMplfmOF0nKiTl5ZI4YQkNh1stxtIB4kVuokav32rjiOdA9x79Ww7EOqQC6Zm0dzZT0Nbr9NRIpIVuokKHb1D/OcrNbx3Vi4VJVlOx4la86ZkkBAbw4YDbU5HiUhW6CYq/PLV/XQNuPn6B85zOkpUS4h1sWBKJtubOugddDsdJ+JYoZuId6Szn/9+4wDL50+mbLLdfchpFSVZuL3K5nq7cjTQrNBNxPvpS/twe5SvXDXL6SgGyM9IoigrmQ0H2uzgaIBZoZuIdqC1h8crG7hlSRFF2clOxzE+S0qyaO0eoOaoTdgVSFboJqL9+/N7SIiN4QvvKx17YzNu5hZmkJYYy2s1duOLQLJCNxFrR1MHf952mE9fUkJumt2FKJTExsRw8bRsao52c7ijz+k4EcMK3UQkVeVf1u5iQnIcd1w2zek45iQqSrKJd8Xw+j7bSw8UK3QTkf62t4U39x/ji1eUkm5znYekpHgXi4snsLXxOB19Nr9LIPhV6CKyTET2iEiNiNxzkue/IiLVIrJNRF4SkamBj2qMfzxe5fvP7qYoK5lbl9iPYihbOj0HVXjDxtIDYsxCFxEX8CBwNVAGrBSRslGbbQbKVXUe8CTww0AHNcZfT21qZHdzF99YNssm4ApxWSnxLJiSyYYDx2wWxgDw56e9AqhR1VpVHQRWA8tHbqCqr6jqickZ1gOFgY1pjH/6Bj088Pxe5k/J5Nq5+U7HMX5476w83B7lNRtLP2f+FHoB0DBiudG37lQ+DTx7LqGMOVu/eeMAzZ39/NPV59kEXGEiJy3B9tIDJKB/j4rIbUA58KNTPH+niFSJSFVLS0sg39oYjnUP8Iu/7ufK2RNZMi3b6TjmDLz3vDw8XuXVvdYL58KfQm8CpoxYLvStexcRuRL4JnC9qg6c7IVUdZWqlqtqeW6u3S3GBNbPXq6hb8jDPVfbBFzhJif1xF56G8d7B52OE7b8KfRKoFRESkQkHlgBrBm5gYgsBH7FcJkfDXxMY07vQGsPv1t/kI9eMIUZealOxzFn4crZEwF4vvqIw0nCV+xYG6iqW0TuAtYBLuA3qrpTRO4HqlR1DcNDLKnAH3zjlvWqen0Qc5sAe2xD/Vl/7y1LigKY5MypKvf9cQdJcS6+dKVd4h+uMpPjWTojh7/tbeHi6dlh/TPplDELHUBV1wJrR627b8TjKwOcyxi/Pbujmdf2tfKd68rIS0t0Oo45B++ZmUtVXRtrtzdzx6UldmD7DNlJuiasdQ+4uf9P1Zw/OZ3bLrSLiMJdYpyLK2ZPpO5YDzsOdTodJ+xYoZuw9uMX9tLc2c/3PjSHWJf9OEeCC4qzyM9I5C/bDjEw5HE6Tlix3wATtqrq2vjNGwe47cIiFhVNcDqOCRBXjLB8/mQ6+928tNvOsTgTVugmLPUOuvnaH7ZSkJnEvVfPdjqOCbCi7BQuKJ7Am/tbbXrdM2CFbsLSD5/bQ92xXn5043xSEvw6tm/CzAfKJpEY5+KZzU14vHarOn/Yb4IJOy/vPsLDb9Zx0bRsDrT2cKC1Z1zf/1xOpzP+S06I5bp5k3m8qoE3alq5bKZdjDgW20M3YaWhrZcvP76Vsvx0ls2Z5HQcE2TzCjMoy0/nxV1HONrZ73SckGeFbsLGgNvDXY9twutVfnHbIuLsrJaIJyIsXzCZOFcMT21qtKGXMdhvhAkLqso3n9nB1sYOfnTTPKZmpzgdyYyTtMQ4rl8wmYb2Pl7ZY2e9nI4VugkLP3lxH09ubOSLV5SybI7Ncx5t5hdmsqgok1d2H6W2tdvpOCHLCt2EvNVv1/PTl/Zx0+JCvmxztUSt6+ZPJislnicqG+gdcDsdJyRZoZuQ9tiGeu59ZjvvmZnLv3xkrs3tEcUSYl2sqCiiZ8DDU5saUbXx9NGs0E3Ieui1Wv7pme1cPjOXX31ssR0ENRRkJvGBOZPY1dzF+gNtTscJOXYeugk5A24P//znXTy6/iDXzJ3ETz660G72bN6xdHo2+4928+z2wxRnJ5OfkeR0pJBhvyUmpDS293Lzr9bz6PqD3HFpCf+xwsrcvJuIcMPiQpLiXPz+7QabwGsE+00xIWHA7eHBV2q46oFX2X+0m1/etohvXltmMyiak0pNiOXmC6ZwrHuApzc32Xi6jw25GEd19g/xZFUjD79ZR31bLx84fyLfuraMKVnJTkczIW56birvP38S63Y2U5SVzNIZOU5HcpwVuhlXHX1DNLT1srm+nTdqjvHqvhZ6Bz0sLMrk/uXnc/msPKcjmjByWWkODW29PLvjMAWZSRTnRPcFZ34VuogsA37K8D1FH1LV7496/jLgJ8A8YIWqPhnooCa0DLq91Bzt5lDH8NV7Rzr76ewbonvA886fvwrveuz2KN0jzh8uyExi+YICVlZMYV5hpgOfwoQ7EeHGxYU8+EoNv6+s5673ziAtMc7pWI4Zs9BFxAU8CFwFNAKVIrJGVatHbFYP3A58LRghTWhQVWpbe9hwoI09zZ0MeRQBpuWmUDghmeLsFFISYokREAFBOHHauAAxMUJ+RiJTJiQzOz+dqdnJdl65OWeJcS5uWVLEL/+2n9WVDXxqaYnTkRzjzx56BVCjqrUAIrIaWA68U+iqWud7zhuEjCYEHDzWw/PVRzjQ2kNKvItFRROYU5DBlAnJ3L602Ol4JsrlZyTxoQUF/GFjI89XN/Oxi6Lz/rL+FHoB0DBiuRFYEpw4JtQMuD08t6OZDQfaSEuI5YPz8rmgOMsu8jEhZ2HRBOrbenltXyvP7TgclXP+jOtBURG5E7gToKioaDzf2pyFxvZeVlc20N4zyNLp2VxVNing54TbzSJMIF07N5+m43187Q/bmDkxjWm5qU5HGlf+/HY2AVNGLBf61p0xVV2lquWqWp6ba3cfCWWb69tZ9WotXlU+c+k0rp032S7wMSEv1hXDLRVFxLmEz/1uE72D0TWJlz+/oZVAqYiUiEg8sAJYE9xYximqynM7mvnDxkamZCXz+ctnUBLlp4KZ8JKZHM9/rFzI3qNd3Pv09qi66GjMQldVN3AXsA7YBTyhqjtF5H4RuR5ARC4QkUbgJuBXIrIzmKFNcHi8ytObmnh1XwsVJVl8ammJ3YDZhKVLS3P56lUz+eOWQzy6/qDTccaNX7+tqroWWDtq3X0jHlcyPBRjwtSQx8vjlQ1UH+7kfeflccV5eXZKoQlr/3D5DDbXH+d7f67m/MkZLJ46welIQWeDoobuATePvFVH9eFOrp2bz5WzJ1qZm7AXEyM8cPMC8jOS+NzvNnIkCm4ybYUe5dp7Brn1oQ0caO3hxsWFNh+GiSgZyXH8+uPldA+4+T+PbqQ/wmdmtEKPYoc7+rjpV2+x63Anty6ZyqKiyP+T1ESfWZPSeODm+WxpOM63/ndHRB8ktUKPUvtburnxF2/R3NHPbz9Zwez8dKcjGRM0y+bk88UrSnly4/DMnpHKCj0KbWs8zk2/fIv+IQ+r77yQi6ZnOx3JmKD70hWlXFU2kX/+yy7erGl1Ok5QWKFHmTdqWlm5aj3J8S6e/NzFzCnIcDqSMeNi+CDpfKblpPD5xzZx8FiP05ECzgo9ivzv5iY++d+VFE5I5qnPXWwXDJmok5Y4fJBUgdv/u5K2nnsw7fgAAAm1SURBVEGnIwWUXTUSBTxe5QfP7WbVq7UsKcli1cfKyUgO3JzRNh+LCSfFOSn8+uPl3PrQBu54pIr/+cwSEuNcTscKCNtDj3BHO/v5xG/eZtWrtXz8oqn87jNLAlrmxoSjC4qz+PHNC9h4sJ27V2/G7YmMmb+t0CPYS7uOsOynr1F1sI0f3DCX+5fPsWlvjfG5dl4+376ujHU7j/D1J7fh9Yb/6Yw25BKBWroG+Oe/VPPHLYeYnZ/Oz1YuYEZemtOxjAk5n1xaQs+Am397fi+JcS7+34fmEBMTvldJW6FHkAG3h8c21PPjF/bSP+Tli1eU8vn3TichNjLGB40Jhs+/dwY9gx5+8df9DLq9/OCGucSG6V+yVugh5mwOMLq9XrY2HGd9bRtNx/tYOiOb714/hxl50TW5vzFnQ0T4xgdmkRjr4scv7qWrf4j/WLkwLA+UWqGHsd4BN1UH23lzfyud/W7mFmTw/RvmcsmMHJtcy5gzICLcfWUp6UmxfPdP1az89Xp+edtiJqYnOh3tjFihhxm310ttSw+b6tvZeagTj1eZnpvCRxYV8u3ryqzIjTkHn1xawqT0RL76h61c97PX+cVti8Nq2l0r9DAw5PGy70gXOw91squ5k/4hL0lxLipKsiifOoH8jCQAK3NjAuDqufmU5KZwxyNV3Pyrt/iHy6fzhfeVhsUtGK3QQ5BXleaOfmpbuqlt7aG2pYdBz3CJl+VnMGdyOtPzUu0URGOC5LxJ6fz5C5dy/5+q+dnLNbxQfYRvX3d+yM97ZIUeAlq6Bth5qIOdhzr5y7bDHGjtoc83b3NOajwLizI5f3IGJTkpuML4lCpjwklGUhz/fvN8rp4zif/7xx2s/PV63jsrl69cNYu5haE5B5JfhS4iy4CfAi7gIVX9/qjnE4BHgMXAMeCjqloX2KjhrX/IQ2N7H/VtPRw81uv76qH6cCdHOgfe2S4rJZ6yyelMy0lhWm4qGUl2VacxTrqybCKXlObw8Jt1PPhKDdf9/HUWFWVy24VTuapsImmJofM7Omahi4gLeBC4CmgEKkVkjapWj9js00C7qs4QkRXAD4CPBiOw01SV/iEvHX1DdPYP0dE3REev71/f19t1bfQMuOnud9M14Karf4j+oXdfWhwfG0N2SjyTM5JYPDWLyZmJTM5ICstTpYyJdIlxLj77nuncsqSIJ6saeXT9Qb7yxFbiXTFcPCObS2bkUF6cRVl+uqNj7f7soVcANapaCyAiq4HlwMhCXw58x/f4SeDnIiIahFuDDLg9DLi9xIgggAgIMvyvbzTC41WGPIrb48XtVYY8Xtwexe1V3N7hxwNuDz0DHnoH3fQOeugZ9NA74H7n394hDz0Dbjr7Rpb18PLgGPM+JMTGkJIQS1pCLHlpCUzPTSUtMZbMpDiyU+LJSk0gJd5lBzGNCTPpiXF86pISbr+4mE317azb2cwL1Uf4654WAGJjhOKcFKbnpjAxPZHc1ARy0xLISU0gKzWelPhYkuNdZKfGkxwf+BFvf16xAGgYsdwILDnVNqrqFpEOIBsI+CzyD79Rx78+uzvQL/suyfEukuNjSUlwkZ4YR3pSLJMyEslIiiM9KY6Mk3ylJw7/m5YYyxNVjUHNZ4xxVkyMUF6cRXlxFt+8toyjnf1U1rWz81AH+452U3O0m7f2H6Oz333S7//e8vP52EXFAc81rgdFReRO4E7fYreI7BnP9x9HOQThP7Ox3Dp+b+XI5xtHkf75IMI/460h/vk+/gP4+Nl/+9RTPeFPoTcBU0YsF/rWnWybRhGJBTIYPjj6Lqq6Cljlx3uGNRGpUtVyp3MEi32+8BfpnzHSP9+p+DN6XwmUikiJiMQDK4A1o7ZZA3zC9/hG4OVgjJ8bY4w5tTH30H1j4ncB6xg+bfE3qrpTRO4HqlR1DfBfwKMiUgO0MVz6xhhjxpFfY+iquhZYO2rdfSMe9wM3BTZaWIv0YSX7fOEv0j9jpH++kxIbGTHGmMhgk4EYY0yEsEIPIBH5jYgcFZEdTmcJBhGZIiKviEi1iOwUkbudzhRIIpIoIm+LyFbf5/uu05mCQURcIrJZRP7sdJZgEJE6EdkuIltEpMrpPOPJhlwCSEQuA7qBR1R1jtN5Ak1E8oF8Vd0kImnARuBDo6aBCFsyfOluiqp2i0gc8Dpwt6qudzhaQInIV4ByIF1VP+h0nkATkTqgXFVD9jz0YLE99ABS1VcZPssnIqnqYVXd5HvcBexi+CrhiKDDun2Lcb6viNrjEZFC4FrgIaezmMCzQjdnRUSKgYXABmeTBJZvOGILcBR4QVUj6vMBPwG+AZx+QqLwpsDzIrLRd3V61LBCN2dMRFKBp4AvqWqn03kCSVU9qrqA4SuiK0QkYobOROSDwFFV3eh0liC7RFUXAVcDn/cNhUYFK3RzRnxjy08B/6OqTzudJ1hU9TjwCrDM6SwBtBS43jfGvBp4n4j8ztlIgaeqTb5/jwLPMDxjbFSwQjd+8x00/C9gl6o+4HSeQBORXBHJ9D1OYvgeAMGd2nMcqeq9qlqoqsUMX839sqre5nCsgBKRFN8Be0QkBXg/EJFnnZ2MFXoAicjvgbeAWSLSKCKfdjpTgC0FPsbwnt0W39c1TocKoHzgFRHZxvAcRi+oakSe2hfBJgKvi8hW4G3gL6r6nMOZxo2dtmiMMRHC9tCNMSZCWKEbY0yEsEI3xpgIYYVujDERwgrdGGMihBW6MedIRP4qIuW+x3UikuN0JhOdrNCNGYMMs98VE/Lsh9REJBH5iojs8H19SUS+LyKfH/H8d0Tka77HXxeRShHZdmIOdBEpFpE9IvIIw1caThGRX4hIVSTPlW7Cm1/3FDUmnIjIYuCTwBJAGJ4R8jaGZxp80LfZzcAHROT9QCnD830IsMY3mVO9b/0nTsyHLiLfVNU2EXEBL4nIPFXdNo4fzZjTskI3kegS4BlV7QEQkaeBS4E8EZkM5ALtqtrgu+vS+4HNvu9NZbjI64GDo25ucbNvOtZYhqcJKAOs0E3IsEI30eQPwI3AJOBx3zoB/lVVfzVyQ9987z0jlkuArwEXqGq7iDwMJAY/sjH+szF0E4leAz4kIsm+Gfc+7Fv3OMOzDN7IcLkDrAM+5ZvjHREpEJG8k7xmOsMF3yEiExmea9uYkGJ76Cbi+O55+jDDs+0BPKSqmwF8U6s2qeph37bPi8hs4K3h2YHpZni83TPqNbeKyGaGp9NtAN4Yj89izJmw2RaNMSZC2JCLMcZECCt0Y4yJEFboxhgTIazQjTEmQlihG2NMhLBCN8aYCGGFbowxEcIK3RhjIsT/B3NodEW8saGqAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYk3hkmusIl7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "b71045f9-48ac-49b4-8afc-14a8ad3f2c9a"
      },
      "source": [
        "# engineer new feature\n",
        "\n",
        "df['Great'] = df['overall'] >= 4\n",
        "df['Great'].describe()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count       423\n",
              "unique        2\n",
              "top       False\n",
              "freq        241\n",
              "Name: Great, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olLpTFHrtmtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.dropna(subset=['overall'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ7eONFjoekP",
        "colab_type": "text"
      },
      "source": [
        "### How is your target distributed?\n",
        "\n",
        "For a classification problem, determine: How many classes? Are the classes imbalanced?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdC93E-xoekP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50309b6a-c78c-45d9-e7a4-e9faf23d7ad5"
      },
      "source": [
        "y = df['Great']\n",
        "y.nunique()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV1vN15Ouyht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c1c7a272-757f-4b2b-8cd9-2d009e5321e4"
      },
      "source": [
        "y.value_counts(normalize=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    0.567696\n",
              "True     0.432304\n",
              "Name: Great, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv9rubhQoekU",
        "colab_type": "text"
      },
      "source": [
        "# Avoid leakage of information from test to train or from target to features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIfdFzTjoekV",
        "colab_type": "text"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGyJUI2BoekX",
        "colab_type": "text"
      },
      "source": [
        "Overfitting is our enemy in applied machine learning, and leakage is often the cause.\n",
        "\n",
        "> Make sure your training features do not contain data from the “future” (aka time traveling). While this might be easy and obvious in some cases, it can get tricky. … If your test metric becomes really good all of the sudden, ask yourself what you might be doing wrong. Chances are you are time travelling or overfitting in some way. — [Xavier Amatriain](https://www.quora.com/What-are-some-best-practices-for-training-machine-learning-models/answer/Xavier-Amatriain)\n",
        "\n",
        "Choose train, validate, and test sets. Are some observations outliers? Will you exclude them? Will you do a random split or a time-based split? You can (re)read [How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmiL4ZNgoekZ",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn9TB1wsoekb",
        "colab_type": "text"
      },
      "source": [
        "First, begin to **explore and clean your data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px3-jow1oekc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "60af818b-1741-4e3c-9af4-2d8e3347b19f"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Location', 'Burrito', 'Date', 'Neighborhood', 'Address', 'URL', 'Yelp',\n",
              "       'Google', 'Chips', 'Cost', 'Hunger', 'Mass (g)', 'Density (g/mL)',\n",
              "       'Length', 'Circum', 'Volume', 'Tortilla', 'Temp', 'Meat', 'Fillings',\n",
              "       'Meat:filling', 'Uniformity', 'Salsa', 'Synergy', 'Wrap', 'overall',\n",
              "       'Rec', 'Reviewer', 'Notes', 'Unreliable', 'NonSD', 'Beef', 'Pico',\n",
              "       'Guac', 'Cheese', 'Fries', 'Sour cream', 'Pork', 'Chicken', 'Shrimp',\n",
              "       'Fish', 'Rice', 'Beans', 'Lettuce', 'Tomato', 'Bell peper', 'Carrots',\n",
              "       'Cabbage', 'Sauce', 'Salsa.1', 'Cilantro', 'Onion', 'Taquito',\n",
              "       'Pineapple', 'Ham', 'Chile relleno', 'Nopales', 'Lobster', 'Queso',\n",
              "       'Egg', 'Mushroom', 'Bacon', 'Sushi', 'Avocado', 'Corn', 'Zucchini',\n",
              "       'Great'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSSzL87exKbL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "70fe98bc-eae6-49c4-95fb-8841bdbdc0b6"
      },
      "source": [
        "df['Burrito'].unique()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['California ', 'Carnitas', 'Carne asada', 'California',\n",
              "       'combo chicken', 'Monster California', 'Carne Asada',\n",
              "       'Surf & Turf', 'Chile verde pork', 'battered fish ',\n",
              "       'Surf and turf ', 'Adobada ', 'Barbacoa', '2 in 1', 'Adobado',\n",
              "       'Shredded beef', 'Hawaiian', 'Bandido', 'Campeon', 'carne asada',\n",
              "       'California chicken', 'Azteca', 'Lobster', 'Al pastor', 'Custom',\n",
              "       'Machaca', 'Quesaburro', 'Philly ', 'Quesa', 'Surf and turf',\n",
              "       'Mahi', 'Addiction', 'Oaxacalifornia', \"Deborah's special\",\n",
              "       'Chicken nopalito', 'Adobada', 'Chicken', 'California Everything',\n",
              "       'Chile relleno and carnitas', 'California (only cheese)', 'Fish',\n",
              "       'Chimichanga beef', 'Pastor', 'El Hawaiiano ', 'Shrimp',\n",
              "       'El Rusio', 'Bacon breakfast', 'Chile Relleno', 'Bomb', 'Arizona',\n",
              "       'California Burrito', '619 Burrito Original', 'Chicken asada',\n",
              "       'Carne adobada ', 'Bean and cheese', 'Pokirrito classic ',\n",
              "       'Mauna Lani', 'Especial ', 'Ranchero steak', 'Vegetarian',\n",
              "       'Colimas burrito', 'Bean and rice grande size', 'Surf and Turf',\n",
              "       'Bean and Cheese', 'Pollo california', 'California breakfast',\n",
              "       'Baja monster', 'Local', 'Fusion', 'California Surf', 'Super',\n",
              "       'Mixed', 'Carne asada everything', 'Pollo asado', 'Tilapia one',\n",
              "       'Surfin California', 'Nutty', 'Veg Out', 'Veggie',\n",
              "       'California - Steak', 'California - Pork Adobada',\n",
              "       'California - Chicken', 'Holy Moly', 'Barbacoa ',\n",
              "       'California + Guac + sour cream', 'Al Pastor', 'Pollo adobado',\n",
              "       'Asada', 'California Chipotle', \"Dave's California\",\n",
              "       'Chicken and rice', 'Breakfast', 'Fajitas ', 'Tejano',\n",
              "       'Shrimp with guac', 'Bean & cheese', 'Al pastor ',\n",
              "       'Carne asada supreme', 'Cali Diablo', 'Pork california',\n",
              "       'Bitchin California', 'Tijuana', 'Combo chicken',\n",
              "       'Chicken avocado', 'Cabeza', 'Chicken Shawarma', 'Hot cheetos',\n",
              "       'Spicy a la Diabla', 'California everything',\n",
              "       'California everything mini', 'TGunz', 'Al pastor tradicional ',\n",
              "       'Grilled fish salmon', 'Cheese steak', 'California Surf and Turf',\n",
              "       'Shrimp california', 'carne asada ', 'fried fish',\n",
              "       'Steak everything ', 'Golden State', 'Steak fajitas', 'Hashbrown',\n",
              "       'Steak with guacamole', 'Chile Verde (pork)', 'Supreme chicken',\n",
              "       'Carnitas ', 'Alambre california', 'Surfin california',\n",
              "       'Ado-haba california', 'Ala tingada california', 'La Paz',\n",
              "       'Pollo Asado'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBAkrw47xsIN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "4242bb0a-1bab-4a80-eca6-df99c7859608"
      },
      "source": [
        "# Combine and reduce number of burrito categories\n",
        "df['Burrito'] =df['Burrito'].str.lower()\n",
        "df['Burrito'].nunique()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "123"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0JcYruvyODs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Simplify to four primary types of burritos\n",
        "\n",
        "california = df['Burrito'].str.contains('california')\n",
        "asada = df['Burrito'].str.contains('asada')\n",
        "surf = df['Burrito'].str.contains('surf')\n",
        "carnitas = df['Burrito'].str.contains('carnitas')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wboe56rUyeeP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "0f538eb5-5c28-4be2-cc24-62ced8ca9beb"
      },
      "source": [
        "california.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     True\n",
              "1     True\n",
              "2    False\n",
              "3    False\n",
              "4     True\n",
              "Name: Burrito, dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHuXtYKc4kQ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "63e3c651-04fa-404d-eb0d-b8cbba128cf0"
      },
      "source": [
        "df.loc[california, 'Burrito'] = 'California'\n",
        "df.loc[asada, 'Burrito'] = 'Asada'\n",
        "df.loc[surf, 'Burrito'] = 'Surf & Turf'\n",
        "df.loc[carnitas, 'Burrito'] = 'Carnitas'\n",
        "df.loc[-california & -asada & -surf & -carnitas, 'Burrito'] = 'Other'\n",
        "\n",
        "df['Burrito'].value_counts()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[item] = s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "California     169\n",
              "Other          156\n",
              "Asada           43\n",
              "Surf & Turf     28\n",
              "Carnitas        25\n",
              "Name: Burrito, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eamv6_cDxJbP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "26193303-a1f2-4cf6-bd69-08805199f8c7"
      },
      "source": [
        "df.columns # What might sense to drop"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Location', 'Burrito', 'Date', 'Neighborhood', 'Address', 'URL', 'Yelp',\n",
              "       'Google', 'Chips', 'Cost', 'Hunger', 'Mass (g)', 'Density (g/mL)',\n",
              "       'Length', 'Circum', 'Volume', 'Tortilla', 'Temp', 'Meat', 'Fillings',\n",
              "       'Meat:filling', 'Uniformity', 'Salsa', 'Synergy', 'Wrap', 'overall',\n",
              "       'Rec', 'Reviewer', 'Notes', 'Unreliable', 'NonSD', 'Beef', 'Pico',\n",
              "       'Guac', 'Cheese', 'Fries', 'Sour cream', 'Pork', 'Chicken', 'Shrimp',\n",
              "       'Fish', 'Rice', 'Beans', 'Lettuce', 'Tomato', 'Bell peper', 'Carrots',\n",
              "       'Cabbage', 'Sauce', 'Salsa.1', 'Cilantro', 'Onion', 'Taquito',\n",
              "       'Pineapple', 'Ham', 'Chile relleno', 'Nopales', 'Lobster', 'Queso',\n",
              "       'Egg', 'Mushroom', 'Bacon', 'Sushi', 'Avocado', 'Corn', 'Zucchini',\n",
              "       'Great'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5NN5-oO5a3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "6f72dbfd-e0cc-4ebb-94cf-c7c18adb785e"
      },
      "source": [
        "df = df.drop(columns=['Notes', 'Location', 'Reviewer', 'Address', 'URL', 'Neighborhood'])\n",
        "\n",
        "df.isna().sum().sort_values()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Burrito       0\n",
              "overall       0\n",
              "Tortilla      0\n",
              "Great         0\n",
              "Date          0\n",
              "           ... \n",
              "Ham         419\n",
              "Lobster     420\n",
              "Zucchini    420\n",
              "Carrots     420\n",
              "Queso       421\n",
              "Length: 61, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoUX-9hy55qb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.fillna('Missing')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcoePIXGoekl",
        "colab_type": "text"
      },
      "source": [
        "Next, do a **time-based split:**\n",
        "\n",
        "- Train on reviews from 2016 & earlier. \n",
        "- Validate on 2017. \n",
        "- Test on 2018 & later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kekkbQT2oekm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "4194a156-4855-4af3-c56a-9aff1ed53f78"
      },
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
        "df['Date']"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     2016-01-18\n",
              "1     2016-01-24\n",
              "2     2016-01-24\n",
              "3     2016-01-24\n",
              "4     2016-01-27\n",
              "         ...    \n",
              "418   2019-08-27\n",
              "419   2019-08-27\n",
              "420   2019-08-27\n",
              "421   2019-08-27\n",
              "422   2019-08-27\n",
              "Name: Date, Length: 421, dtype: datetime64[ns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKz2Eu-x6OGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = df[df['Date'].dt.year <= 2016]\n",
        "val = df[df['Date'].dt.year == 2017]\n",
        "test = df[df['Date'].dt.year >= 2018]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49RI0JgG6oEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b9576b9-f497-4faf-b075-f9a717dd83ca"
      },
      "source": [
        "train.shape, val.shape, test.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((298, 61), (85, 61), (38, 61))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZtVQvpVoekt",
        "colab_type": "text"
      },
      "source": [
        "Begin to choose which features, if any, to exclude. **Would some features “leak” future information?**\n",
        "\n",
        "What happens if we _DON’T_ drop features with leakage?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRLuXrtdoekt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25a44243-aeb4-4c83-80b0-46f0b8060132"
      },
      "source": [
        "# Try a shallow decision tree as a fast, first model\n",
        "\n",
        "import category_encoders as ce\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "target = 'Great'\n",
        "features = train.columns.drop([target, 'Date'])\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    DecisionTreeClassifier(max_depth=3)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBz_IDGqoeky",
        "colab_type": "text"
      },
      "source": [
        "Drop the column with “leakage”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABQUtGTGoeky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "5c089db8-f9d0-481b-ceb9-b5badcc5f143"
      },
      "source": [
        "# This is to good, lets fix it\n",
        "# We'll take a look at the decision tree to see what the model learned\n",
        "\n",
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "tree = pipeline.named_steps['decisiontreeclassifier']\n",
        "\n",
        "dot_data = export_graphviz(\n",
        "    tree,\n",
        "    out_file=None,\n",
        "    feature_names = X_train.columns,\n",
        "    class_names= y_train.unique().astype(str),\n",
        "    filled=True,\n",
        "    impurity=False,\n",
        "    proportion=True\n",
        ")\n",
        "\n",
        "graphviz.Source(dot_data)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f3fcad4cba8>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"260pt\" height=\"165pt\"\n viewBox=\"0.00 0.00 260.00 165.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 161)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-161 256,-161 256,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"#f7d8c2\" stroke=\"#000000\" points=\"199,-157 52,-157 52,-89 199,-89 199,-157\"/>\n<text text-anchor=\"middle\" x=\"125.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">overall &lt;= 3.95</text>\n<text text-anchor=\"middle\" x=\"125.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 100.0%</text>\n<text text-anchor=\"middle\" x=\"125.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.591, 0.409]</text>\n<text text-anchor=\"middle\" x=\"125.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = False</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#e58139\" stroke=\"#000000\" points=\"117,-53 0,-53 0,0 117,0 117,-53\"/>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 59.1%</text>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1.0, 0.0]</text>\n<text text-anchor=\"middle\" x=\"58.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = False</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M101.8783,-88.9777C95.7113,-80.0954 89.0539,-70.5067 82.8499,-61.5711\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"85.6497,-59.4666 77.0715,-53.2485 79.8997,-63.4589 85.6497,-59.4666\"/>\n<text text-anchor=\"middle\" x=\"72.6325\" y=\"-74.1512\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#399de5\" stroke=\"#000000\" points=\"252,-53 135,-53 135,0 252,0 252,-53\"/>\n<text text-anchor=\"middle\" x=\"193.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 40.9%</text>\n<text text-anchor=\"middle\" x=\"193.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.0, 1.0]</text>\n<text text-anchor=\"middle\" x=\"193.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = True</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M149.4743,-88.9777C155.7333,-80.0954 162.4901,-70.5067 168.7867,-61.5711\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"171.7521,-63.4389 174.6513,-53.2485 166.0301,-59.4068 171.7521,-63.4389\"/>\n<text text-anchor=\"middle\" x=\"178.9191\" y=\"-74.1815\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAy35uqw9w_F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76151e60-2e56-4e40-f98a-812ee1daacd6"
      },
      "source": [
        "# Lets drop the leaky overall column\n",
        "# Its a problem because we used it to engineer our target\n",
        "\n",
        "features = train.columns.drop([target, 'Date', 'overall'])\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    DecisionTreeClassifier(max_depth=3)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri44hWc1-IjJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "ab6b5472-23a0-4b5c-8a27-2966ff589f2d"
      },
      "source": [
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "tree = pipeline.named_steps['decisiontreeclassifier']\n",
        "\n",
        "dot_data = export_graphviz(\n",
        "    tree,\n",
        "    out_file=None,\n",
        "    feature_names = X_train.columns,\n",
        "    class_names= y_train.unique().astype(str),\n",
        "    filled=True,\n",
        "    impurity=False,\n",
        "    proportion=True\n",
        ")\n",
        "\n",
        "graphviz.Source(dot_data)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f3fcaddd128>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"1265pt\" height=\"373pt\"\n viewBox=\"0.00 0.00 1264.50 373.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 369)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-369 1260.5,-369 1260.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"#f7d8c2\" stroke=\"#000000\" points=\"680,-365 533,-365 533,-297 680,-297 680,-365\"/>\n<text text-anchor=\"middle\" x=\"606.5\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Fillings &lt;= 4.5</text>\n<text text-anchor=\"middle\" x=\"606.5\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 100.0%</text>\n<text text-anchor=\"middle\" x=\"606.5\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.591, 0.409]</text>\n<text text-anchor=\"middle\" x=\"606.5\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = False</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#ea9a61\" stroke=\"#000000\" points=\"537,-261 390,-261 390,-193 537,-193 537,-261\"/>\n<text text-anchor=\"middle\" x=\"463.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Synergy &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"463.5\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50.0%</text>\n<text text-anchor=\"middle\" x=\"463.5\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.832, 0.168]</text>\n<text text-anchor=\"middle\" x=\"463.5\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = False</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M559.6765,-296.9465C546.5902,-287.4293 532.247,-276.9978 518.7241,-267.163\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"520.5747,-264.1812 510.4287,-261.13 516.4575,-269.8423 520.5747,-264.1812\"/>\n<text text-anchor=\"middle\" x=\"514.3278\" y=\"-282.1241\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#a3d2f3\" stroke=\"#000000\" points=\"845,-261 698,-261 698,-193 845,-193 845,-261\"/>\n<text text-anchor=\"middle\" x=\"771.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Meat &lt;= 3.5</text>\n<text text-anchor=\"middle\" x=\"771.5\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50.0%</text>\n<text text-anchor=\"middle\" x=\"771.5\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.349, 0.651]</text>\n<text text-anchor=\"middle\" x=\"771.5\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = True</text>\n</g>\n<!-- 0&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>0&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M660.5272,-296.9465C675.9115,-287.2497 692.8016,-276.6039 708.6621,-266.6069\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"710.758,-269.4232 717.3514,-261.13 707.0254,-263.5013 710.758,-269.4232\"/>\n<text text-anchor=\"middle\" x=\"711.8227\" y=\"-281.811\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#fcf0e8\" stroke=\"#000000\" points=\"312,-157 165,-157 165,-89 312,-89 312,-157\"/>\n<text text-anchor=\"middle\" x=\"238.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Tortilla &lt;= 3.9</text>\n<text text-anchor=\"middle\" x=\"238.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 10.7%</text>\n<text text-anchor=\"middle\" x=\"238.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.531, 0.469]</text>\n<text text-anchor=\"middle\" x=\"238.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = False</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M389.8266,-192.9465C367.9738,-182.8457 343.8932,-171.7151 321.4922,-161.3608\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"322.8847,-158.1487 312.3389,-157.13 319.9477,-164.5028 322.8847,-158.1487\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"#e78d4c\" stroke=\"#000000\" points=\"537,-157 390,-157 390,-89 537,-89 537,-157\"/>\n<text text-anchor=\"middle\" x=\"463.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Temp &lt;= 14.5</text>\n<text text-anchor=\"middle\" x=\"463.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 39.3%</text>\n<text text-anchor=\"middle\" x=\"463.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.915, 0.085]</text>\n<text text-anchor=\"middle\" x=\"463.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = False</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M463.5,-192.9465C463.5,-184.776 463.5,-175.9318 463.5,-167.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"467.0001,-167.13 463.5,-157.13 460.0001,-167.13 467.0001,-167.13\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#efb185\" stroke=\"#000000\" points=\"147,-53 0,-53 0,0 147,0 147,-53\"/>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6.0%</text>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.722, 0.278]</text>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = False</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M180.3272,-88.9777C163.182,-78.9504 144.4975,-68.0228 127.618,-58.1508\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"129.3724,-55.1223 118.9734,-53.095 125.8385,-61.1648 129.3724,-55.1223\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#88c4ef\" stroke=\"#000000\" points=\"312,-53 165,-53 165,0 312,0 312,-53\"/>\n<text text-anchor=\"middle\" x=\"238.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4.7%</text>\n<text text-anchor=\"middle\" x=\"238.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.286, 0.714]</text>\n<text text-anchor=\"middle\" x=\"238.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = True</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M238.5,-88.9777C238.5,-80.7364 238.5,-71.887 238.5,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"242.0001,-63.2484 238.5,-53.2485 235.0001,-63.2485 242.0001,-63.2484\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#e78a48\" stroke=\"#000000\" points=\"462.5,-53 330.5,-53 330.5,0 462.5,0 462.5,-53\"/>\n<text text-anchor=\"middle\" x=\"396.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 38.6%</text>\n<text text-anchor=\"middle\" x=\"396.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.93, 0.07]</text>\n<text text-anchor=\"middle\" x=\"396.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = False</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M439.8783,-88.9777C433.7113,-80.0954 427.0539,-70.5067 420.8499,-61.5711\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"423.6497,-59.4666 415.0715,-53.2485 417.8997,-63.4589 423.6497,-59.4666\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"#399de5\" stroke=\"#000000\" points=\"598,-53 481,-53 481,0 598,0 598,-53\"/>\n<text text-anchor=\"middle\" x=\"539.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 0.7%</text>\n<text text-anchor=\"middle\" x=\"539.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.0, 1.0]</text>\n<text text-anchor=\"middle\" x=\"539.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = True</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M490.2948,-88.9777C497.3622,-80.0039 504.9976,-70.3089 512.0967,-61.295\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"514.9963,-63.2701 518.4338,-53.2485 509.497,-58.9391 514.9963,-63.2701\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"#f0b68c\" stroke=\"#000000\" points=\"845,-157 698,-157 698,-89 845,-89 845,-157\"/>\n<text text-anchor=\"middle\" x=\"771.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Tortilla &lt;= 3.75</text>\n<text text-anchor=\"middle\" x=\"771.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 14.8%</text>\n<text text-anchor=\"middle\" x=\"771.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.705, 0.295]</text>\n<text text-anchor=\"middle\" x=\"771.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = False</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M771.5,-192.9465C771.5,-184.776 771.5,-175.9318 771.5,-167.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"775.0001,-167.13 771.5,-157.13 768.0001,-167.13 775.0001,-167.13\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"#6ab6ec\" stroke=\"#000000\" points=\"1078,-157 961,-157 961,-89 1078,-89 1078,-157\"/>\n<text text-anchor=\"middle\" x=\"1019.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Meat &lt;= 7.5</text>\n<text text-anchor=\"middle\" x=\"1019.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 35.2%</text>\n<text text-anchor=\"middle\" x=\"1019.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.2, 0.8]</text>\n<text text-anchor=\"middle\" x=\"1019.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = True</text>\n</g>\n<!-- 8&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>8&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M845.2367,-196.0782C878.8944,-181.9636 918.4994,-165.3551 951.4406,-151.541\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"953.1204,-154.632 960.9888,-147.537 950.4133,-148.1766 953.1204,-154.632\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#e89153\" stroke=\"#000000\" points=\"762.5,-53 616.5,-53 616.5,0 762.5,0 762.5,-53\"/>\n<text text-anchor=\"middle\" x=\"689.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 8.7%</text>\n<text text-anchor=\"middle\" x=\"689.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.885, 0.115]</text>\n<text text-anchor=\"middle\" x=\"689.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = False</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M742.5899,-88.9777C734.8866,-79.9123 726.5581,-70.111 718.8324,-61.0192\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"721.3718,-58.6025 712.2293,-53.2485 716.0375,-63.1352 721.3718,-58.6025\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"#d7ebfa\" stroke=\"#000000\" points=\"928,-53 781,-53 781,0 928,0 928,-53\"/>\n<text text-anchor=\"middle\" x=\"854.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6.0%</text>\n<text text-anchor=\"middle\" x=\"854.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.444, 0.556]</text>\n<text text-anchor=\"middle\" x=\"854.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = True</text>\n</g>\n<!-- 9&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>9&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M800.7627,-88.9777C808.5599,-79.9123 816.99,-70.111 824.8099,-61.0192\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"827.6262,-63.1123 831.4935,-53.2485 822.3191,-58.5477 827.6262,-63.1123\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"#53aae8\" stroke=\"#000000\" points=\"1092.5,-53 946.5,-53 946.5,0 1092.5,0 1092.5,-53\"/>\n<text text-anchor=\"middle\" x=\"1019.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 29.2%</text>\n<text text-anchor=\"middle\" x=\"1019.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.115, 0.885]</text>\n<text text-anchor=\"middle\" x=\"1019.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = True</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1019.5,-88.9777C1019.5,-80.7364 1019.5,-71.887 1019.5,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1023.0001,-63.2484 1019.5,-53.2485 1016.0001,-63.2485 1023.0001,-63.2484\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"#f6d1b7\" stroke=\"#000000\" points=\"1256.5,-53 1110.5,-53 1110.5,0 1256.5,0 1256.5,-53\"/>\n<text text-anchor=\"middle\" x=\"1183.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6.0%</text>\n<text text-anchor=\"middle\" x=\"1183.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [0.611, 0.389]</text>\n<text text-anchor=\"middle\" x=\"1183.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = False</text>\n</g>\n<!-- 12&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>12&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1077.3203,-88.9777C1094.2052,-79.0424 1112.5922,-68.2232 1129.2478,-58.4228\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1131.4585,-61.183 1138.3022,-53.095 1127.9086,-55.1499 1131.4585,-61.183\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXthsZRpBq8N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d9abfc45-8f7a-46a9-f356-fbd4d0e8be7c"
      },
      "source": [
        "y_train.value_counts(normalize=True)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    0.590604\n",
              "True     0.409396\n",
              "Name: Great, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU5KDsufBwDc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9fe610cc-56dd-4a81-f246-d8cd4e513ff3"
      },
      "source": [
        "y_val.value_counts(normalize=True)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    0.552941\n",
              "True     0.447059\n",
              "Name: Great, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RrXzsByoek5",
        "colab_type": "text"
      },
      "source": [
        "# Choose an appropriate evaluation metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83Cokeh4oek7",
        "colab_type": "text"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlABGLBloek9",
        "colab_type": "text"
      },
      "source": [
        "How will you evaluate success for your predictive model? You must choose an appropriate evaluation metric, depending on the context and constraints of your problem.\n",
        "\n",
        "**Classification & regression metrics are different!**\n",
        "\n",
        "- Don’t use _regression_ metrics to evaluate _classification_ tasks.\n",
        "- Don’t use _classification_ metrics to evaluate _regression_ tasks.\n",
        "\n",
        "[Scikit-learn has lists of popular metrics.](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBbp6hWfoek-",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj295nk2oek-",
        "colab_type": "text"
      },
      "source": [
        "For classification problems: \n",
        "\n",
        "As a rough rule of thumb, if your majority class frequency is >= 50% and < 70% then you can just use accuracy if you want. Outside that range, accuracy could be misleading — so what evaluation metric will you choose, in addition to or instead of accuracy? For example:\n",
        "\n",
        "- Precision?\n",
        "- Recall?\n",
        "- ROC AUC?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lxKwEQmoek_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "edbb25fa-90b9-4dd5-d29e-0b381c6bb01a"
      },
      "source": [
        "# Majority class occurs ~57% of the time\n",
        "y.value_counts(normalize=True).max()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5676959619952494"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bipZInoioelD",
        "colab_type": "text"
      },
      "source": [
        "### Precision & Recall\n",
        "\n",
        "Let's review Precision & Recall. What do these metrics mean, in scenarios like these?\n",
        "\n",
        "- Predict great burritos\n",
        "- Predict fraudulent transactions\n",
        "- Recommend Spotify songs\n",
        "\n",
        "[Are false positives or false negatives more costly? Can you optimize for dollars?](https://alexgude.com/blog/machine-learning-metrics-interview/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqOeOebzoelD",
        "colab_type": "text"
      },
      "source": [
        "### ROC AUC \n",
        "\n",
        "Let's also review ROC AUC (Receiver Operating Characteristic, Area Under the Curve).\n",
        "\n",
        "[Wikipedia explains,](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) \"A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. **The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.**\"\n",
        "\n",
        "ROC AUC is the area under the ROC curve. [It can be interpreted](https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it) as \"the expectation that a uniformly drawn random positive is ranked before a uniformly drawn random negative.\" \n",
        "\n",
        "ROC AUC measures **how well a classifier ranks predicted probabilities.** So, when you get your classifier’s ROC AUC score, you need to **use predicted probabilities, not discrete predictions.**\n",
        "\n",
        "ROC AUC ranges **from 0 to 1.** Higher is better. A naive majority class **baseline** will have an ROC AUC score of **0.5**, regardless of class (im)balance.\n",
        "\n",
        "#### Scikit-Learn docs\n",
        "- [User Guide: Receiver operating characteristic (ROC)](https://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc)\n",
        "- [sklearn.metrics.roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)\n",
        "- [sklearn.metrics.roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
        "\n",
        "#### More links\n",
        "- [StatQuest video](https://youtu.be/4jRBRDbJemM)\n",
        "- [Data School article / video](https://www.dataschool.io/roc-curves-and-auc-explained/)\n",
        "- [The philosophical argument for using ROC curves](https://lukeoakdenrayner.wordpress.com/2018/01/07/the-philosophical-argument-for-using-roc-curves/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW51LB9aoelE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76352578-236a-44a6-b65b-b42a79761d87"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "y_pred_proba = pipeline.predict_proba(X_val)[:,-1] # Probability for the last class\n",
        "y_pred_proba[:5]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.06956522, 0.38888889, 0.06956522, 0.06956522, 0.06956522])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yI2O91FFcGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "865dd9b9-5b8e-43b4-c0bb-92d7e44331c5"
      },
      "source": [
        "y_val[:5]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "301    False\n",
              "302    False\n",
              "303    False\n",
              "304    False\n",
              "305    False\n",
              "Name: Great, dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smqHCNLnFaaV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43e1d938-3280-42a0-a629-7af8424d6198"
      },
      "source": [
        "roc_auc_score(y_val, y_pred_proba)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8549832026875699"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x5PBRUVFjis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To understand better, the ROC curve is create bu plotting the true positive rate (TPR)\n",
        "# against the false positive (FPR) at varios threshold settings\n",
        "\n",
        "# Use sklearn to calculate TPR & FPR at various thesholds\n",
        "from sklearn.metrics import roc_curve\n",
        "fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDUVjB-3F_bk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "5c65ba52-e054-421b-81bb-1348e5f67d6c"
      },
      "source": [
        "pd.DataFrame({\n",
        "    'False Postive Rate': fpr,\n",
        "    'True Postive Rate': tpr,\n",
        "    'Threshold': thresholds\n",
        "\n",
        "})"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>False Postive Rate</th>\n",
              "      <th>True Postive Rate</th>\n",
              "      <th>Threshold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.885057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.021277</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.885057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.106383</td>\n",
              "      <td>0.657895</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.710526</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.148936</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.388889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.255319</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>0.277778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.276596</td>\n",
              "      <td>0.842105</td>\n",
              "      <td>0.115385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.069565</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   False Postive Rate  True Postive Rate  Threshold\n",
              "0            0.000000           0.000000   1.885057\n",
              "1            0.021277           0.605263   0.885057\n",
              "2            0.106383           0.657895   0.714286\n",
              "3            0.127660           0.710526   0.555556\n",
              "4            0.148936           0.736842   0.388889\n",
              "5            0.255319           0.789474   0.277778\n",
              "6            0.276596           0.842105   0.115385\n",
              "7            1.000000           1.000000   0.069565"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiSPVIJ_GVXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "93ccc2f4-e492-4aa4-bab9-868b241c2c8b"
      },
      "source": [
        "# See the results on a plot\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(fpr, tpr)\n",
        "plt.plot(fpr, tpr)\n",
        "plt.title('ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Postive Rate');"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cOr-Bo-oelH",
        "colab_type": "text"
      },
      "source": [
        "### Imbalanced classes\n",
        "\n",
        "Do you have highly imbalanced classes?\n",
        "\n",
        "If so, you can try ideas from [Learning from Imbalanced Classes](https://www.svds.com/tbt-learning-imbalanced-classes/):\n",
        "\n",
        "- “Adjust the class weight (misclassification costs)” — most scikit-learn classifiers have a `class_balance` parameter.\n",
        "- “Adjust the decision threshold” — we did this last module. Read [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415).\n",
        "- “Oversample the minority class, undersample the majority class, or synthesize new minority classes” — try the the [imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) library as a stretch goal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7puCsPKFjBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--DUCCVboelH",
        "colab_type": "text"
      },
      "source": [
        "# BONUS: Regression example 🏘️\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "w-F7vxWCoelH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read our NYC apartment rental listing dataset\n",
        "df = pd.read_csv(DATA_PATH+'apartments/renthop-nyc.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA4fZ6kHoelO",
        "colab_type": "text"
      },
      "source": [
        "### Choose your target\n",
        "\n",
        "Which column in your tabular dataset will you predict?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "1qpxmTDXoelP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df['price']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_rgG4N7oelS",
        "colab_type": "text"
      },
      "source": [
        "### How is your target distributed?\n",
        "\n",
        "For a regression problem, determine: Is the target right-skewed?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "zdb7FFJJoelT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Yes, the target is right-skewed\n",
        "import seaborn as sns\n",
        "sns.distplot(y);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5S7fT_moelW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JTst1H_oeld",
        "colab_type": "text"
      },
      "source": [
        "### Are some observations outliers? \n",
        "\n",
        "Will you exclude\n",
        "them?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "BHn3Z2Tooele",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Yes! There are outliers\n",
        "# Some prices are so high or low it doesn't really make sense.\n",
        "# Some locations aren't even in New York City\n",
        "\n",
        "# Remove the most extreme 1% prices, \n",
        "# the most extreme .1% latitudes, &\n",
        "# the most extreme .1% longitudes\n",
        "import numpy as np\n",
        "df = df[(df['price'] >= np.percentile(df['price'], 0.5)) & \n",
        "        (df['price'] <= np.percentile(df['price'], 99.5)) & \n",
        "        (df['latitude'] >= np.percentile(df['latitude'], 0.05)) & \n",
        "        (df['latitude'] < np.percentile(df['latitude'], 99.95)) &\n",
        "        (df['longitude'] >= np.percentile(df['longitude'], 0.05)) & \n",
        "        (df['longitude'] <= np.percentile(df['longitude'], 99.95))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVxS1kisoelh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The distribution has improved, but is still right-skewed\n",
        "y = df['price']\n",
        "sns.distplot(y);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLshoOV8oelk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lghjbYMqoeln",
        "colab_type": "text"
      },
      "source": [
        "### Log-Transform\n",
        "\n",
        "If the target is right-skewed, you may want to “log transform” the target.\n",
        "\n",
        "\n",
        "> Transforming the target variable (using the mathematical log function) into a tighter, more uniform space makes life easier for any [regression] model.\n",
        ">\n",
        "> The only problem is that, while easy to execute, understanding why taking the log of the target variable works and how it affects the training/testing process is intellectually challenging. You can skip this section for now, if you like, but just remember that this technique exists and check back here if needed in the future.\n",
        ">\n",
        "> Optimally, the distribution of prices would be a narrow “bell curve” distribution without a tail. This would make predictions based upon average prices more accurate. We need a mathematical operation that transforms the widely-distributed target prices into a new space. The “price in dollars space” has a long right tail because of outliers and we want to squeeze that space into a new space that is normally distributed. More specifically, we need to shrink large values a lot and smaller values a little. That magic operation is called the logarithm or log for short. \n",
        ">\n",
        "> To make actual predictions, we have to take the exp of model predictions to get prices in dollars instead of log dollars. \n",
        ">\n",
        ">— Terence Parr & Jeremy Howard, [The Mechanics of Machine Learning, Chapter 5.5](https://mlbook.explained.ai/prep.html#logtarget)\n",
        "\n",
        "[Numpy has exponents and logarithms](https://docs.scipy.org/doc/numpy/reference/routines.math.html#exponents-and-logarithms). Your Python code could look like this:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "y_train_log = np.log1p(y_train)\n",
        "model.fit(X_train, y_train_log)\n",
        "y_pred_log = model.predict(X_val)\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "print(mean_absolute_error(y_val, y_pred))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD-cWIamoelo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.distplot(y)\n",
        "plt.title('Original target, in the unit of US dollars');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5lWXCaMoelv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_log = np.log1p(y)\n",
        "sns.distplot(y_log)\n",
        "plt.title('Log-transformed target, in log-dollars');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIwowgFvoelz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_untransformed = np.expm1(y_log)\n",
        "sns.distplot(y_untransformed)\n",
        "plt.title('Back to the original units');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3yi9iLeoel2",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will use your portfolio project dataset for all assignments this sprint. (If you haven't found a dataset yet, do that today. [Review requirements for your portfolio project](https://lambdaschool.github.io/ds/unit2) and choose your dataset.)\n",
        "\n",
        "Complete these tasks for your project, and document your decisions.\n",
        "\n",
        "- Choose your target. Which column in your tabular dataset will you predict?\n",
        "- Is your problem regression or classification?\n",
        "- How is your target distributed?\n",
        "    - Classification: How many classes? Are the classes imbalanced?\n",
        "    - Regression: Is the target right-skewed? If so, you may want to log transform the target.\n",
        "- Choose your evaluation metric(s).\n",
        "    - Classification: Is your majority class frequency >= 50% and < 70% ? If so, you can just use accuracy if you want. Outside that range, accuracy could be misleading. What evaluation metric will you choose, in addition to or instead of accuracy?\n",
        "    - Regression: Will you use mean absolute error, root mean squared error, R^2, or other regression metrics?\n",
        "- Choose which observations you will use to train, validate, and test your model.\n",
        "    - Are some observations outliers? Will you exclude them?\n",
        "    - Will you do a random split or a time-based split?\n",
        "- Begin to clean and explore your data.\n",
        "- Begin to choose which features, if any, to exclude. Would some features \"leak\" future information?\n",
        "\n",
        "Some students worry, ***what if my model isn't “good”?*** Then, [produce a detailed tribute to your wrongness. That is science!](https://twitter.com/nathanwpyle/status/1176860147223867393)"
      ]
    }
  ]
}